Q[,1]= I
for (i in 1:9) {
for (j in 1:9) {
Q[i+1,j+1]=C1[i]*Q[i,j+1]+C2[i]*Q[i,j]+C3[i]*Q[i+1,j]
}
}
Q
source("~/Documents/senior_year/hydrology/HW6_3.R", echo=TRUE)
Q
plot(Q)[,1]
plot(1:10,Q[,1])
plot(1:10,Q[,1])
lines(1:10,Q[,2])
plot(1:10,Q[,1],type="l")
lines(1:10,Q[,2])
plot(1:10,Q[,1],type="l", col="red")
lines(1:10,Q[,2])
plot(1:10,Q[,3],type="l", col="red")
lines(1:10,Q[,4])
plot(1:10,Q[,1],type="l", col="red")
lines(1:10,Q[,2])
plot(1:10,Q[,5],type="l", col="red")
lines(1:10,Q[,6])
plot(1:10,Q[,9],type="l", col="red")
lines(1:10,Q[,10])
plot(1:10,Q[,7],type="l", col="red")
lines(1:10,Q[,8])
plot(1:10,Q[,9],type="l", col="red")
lines(1:10,Q[,10])
plot(1:10,Q[,7],type="l", col="red")
lines(1:10,Q[,8])
plot(1:10,Q[,9],type="l", col="red")
lines(1:10,Q[,10])
plot(1:10,Q[,7],type="l", col="red")
lines(1:10,Q[,8])
source("~/Documents/senior_year/hydrology/HW6.R", echo=TRUE)
p1
source("~/Documents/senior_year/hydrology/HW6_3.R", echo=TRUE)
Q
C1
C2
C3
source("~/Documents/senior_year/hydrology/HW6_3.R", echo=TRUE)
Q
source("~/Documents/senior_year/hydrology/HW6.R", echo=TRUE)
p1
source("~/Documents/senior_year/hydrology/HW6.R", echo=TRUE)
p1
source("~/Documents/senior_year/hydrology/HW6.R", echo=TRUE)
p1
source("~/Documents/senior_year/hydrology/HW6.R", echo=TRUE)
p1
source("~/Documents/senior_year/hydrology/HW6.R", echo=TRUE)
p1
source("~/Documents/senior_year/hydrology/HW6.R", echo=TRUE)
p1
source("~/Documents/senior_year/hydrology/HW6.R", echo=TRUE)
p1
source("~/Documents/senior_year/hydrology/HW6.R", echo=TRUE)
p1
source("~/Documents/senior_year/hydrology/HW6.R", echo=TRUE)
install.packages('matlib')
#install.packages('matlib')
library(matlib)
pA = 0.6
pB = 0.3
pC = 0.1
pDA = 0.02
pDB = 0.03
pDC = 0.04
#Solution: By the law of total probability, to find total probability P(D)
#P(D) = P(A)P(D|A) + P(B)P(D|B) + P(C)P(D|C)
#use function to calculate total probability
pD = ((pA)*(pDA))+((pB)*(pDB))+((pC)*(pDC))
print(pD)
X <- matrix(c(rep(1,6), 10, 5, 7, 19, 11, 8), ncol=2, byrow=FALSE)
y <- c(15, 9, 3, 25, 7, 13)
print(X)
print(y)
#~~~~~~~~~~PART B~~~~~~~~~
#Using OLS to find W hat
w_hat <- solve(t(X) %*% X) %*% t(X) %*% y
print(w_hat)
#~~~~~~~~~~PART C~~~~~~~~~
#To find vector of predicted values Y hat
y_hat <- X %*% w_hat
print(y_hat)
e <- y - y_hat
print(e)
#~~~~~~~~~~PART E~~~~~~~~~
#Compute the mean squared error (MSE)
mse <- mean(e^2)
print(mse)
#~~~~~~~~~~PART F~~~~~~~~~
#Compute the root mean squared error (RMSE)
rmse <- sqrt(mse)
print(rmse)
#~~~~~~~~~~PART G~~~~~~~~~
rmse <- sqrt(mse)
print(rmse)
#~~~~~~~~~~PART G~~~~~~~~~
plot(X[,2], y, main="Scatterplot with Least Squares Line", xlab="x", ylab="y")
abline(w_hat, col="red")
sigma <- function(z) {
1 / (1 + exp(-z))
}
#Plot the function in the domain z âˆˆ [-5, 5]
z <- seq(-5, 5, length.out = 100)
plot(z, sigma(z), type = "l", xlab = "z", ylab = "sigma(z)",
main = "Logistic Sigmoid Function")
source("~/Downloads/CEE697M_HW1_submitted1.R", echo=TRUE)
sigma_prime <- function(z) {
sigma_z <- sigma(z)
(1 - sigma_z) * sigma_z
}
#Finding the derivative using numerical approximation
h <- 0.0001
approx_derivative <- function(z) {
(sigma(z + h) - sigma(z - h)) / (2 * h)
}
all.equal(sigma_prime(z), approx_derivative(z), check.attributes = FALSE)
#~~~~~~~~~~Problem 5~~~~~~ Classifier Performance
#~~~~~~~~~~PART A-H~~~~~~~~
#Confusion matrix creation
conf_matrix <- matrix(c(9650, 17, 265, 68), nrow = 2, byrow = TRUE,
dimnames = list(Observed = c("Class 0", "Class 1"),
Predicted = c("Class 0", "Class 1")))
print(conf_matrix)
#Computing false positives (FP), false negatives (FN), positive observations (P), and predicted positive observations (P*)
FP <- conf_matrix["Class 0", "Class 1"]
FN <- conf_matrix["Class 1", "Class 0"]
P <- sum(conf_matrix["Class 1", ])
P_star <- sum(conf_matrix["Class 0", ])
# Computing precision, recall, F1-score, and accuracy
precision <- conf_matrix["Class 1", "Class 1"] / P_star
recall <- conf_matrix["Class 1", "Class 1"] / P
F1_score <- 2 * precision * recall / (precision + recall)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
# Printing the results of A to H
cat("False positives (FP):", FP, "\n")
cat("False negatives (FN):", FN, "\n")
cat("Positive observations (P):", P, "\n")
cat("Predicted positive observations (P*):", P_star, "\n")
cat("Test precision:", precision, "\n")
cat("Test recall:", recall, "\n")
cat("Test F1-score:", F1_score, "\n")
cat("Test accuracy:", accuracy, "\n")
#~~~~~~~~~~Problem 5~~~~~~ Classifier Performance
#~~~~~~~~~~PART A-H~~~~~~~~
#Confusion matrix creation
conf_matrix <- matrix(c(9650, 17, 265, 68), nrow = 2, byrow = TRUE,
dimnames = list(Observed = c("Class 0", "Class 1"),
Predicted = c("Class 0", "Class 1")))
print(conf_matrix)
#Computing false positives (FP), false negatives (FN), positive observations (P), and predicted positive observations (P*)
FP <- conf_matrix["Class 0", "Class 1"]
FN <- conf_matrix["Class 1", "Class 0"]
P <- sum(conf_matrix["Class 1", ])
P_star <- sum(conf_matrix["Class 0", ])
# Computing precision, recall, F1-score, and accuracy
precision <- conf_matrix["Class 1", "Class 1"] / P_star
recall <- conf_matrix["Class 1", "Class 1"] / P
F1_score <- 2 * precision * recall / (precision + recall)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
# Printing the results of A to H
cat("False positives (FP):", FP, "\n")
cat("False negatives (FN):", FN, "\n")
cat("Positive observations (P):", P, "\n")
cat("Predicted positive observations (P*):", P_star, "\n")
cat("Test precision:", precision, "\n")
cat("Test recall:", recall, "\n")
cat("Test F1-score:", F1_score, "\n")
cat("Test accuracy:", accuracy, "\n")
joint <- matrix(c(1/8, 1/16, 1/32, 1/32,
1/16, 1/8, 1/32, 1/32,
1/16, 1/16, 1/16, 1/16,
1/4, 0, 0, 0), nrow = 4, byrow = TRUE,
dimnames = list(y = c("1", "2", "3", "4"),
x = c("1", "2", "3", "4")))
joint_entropy <- -sum(joint * log2(joint))
print(paste("Joint Entropy H(X,Y) = ", joint_entropy))
#This prints out an NaN not sure why, or if this the right approach to problem
#~~~~~~~~~~PART B~~~~~~~~
#Marginal entropies
#Marginal probabilities first
marg_x <- rowSums(joint)
marg_y <- colSums(joint)
#Back to marginal entropies
H_x <- -sum(marg_x * log2(marg_x))
H_y <- -sum(marg_y * log2(marg_y))
print(paste0("Marginal Entropy H(X) = ", H_x))
print(paste0("Marginal Entropy H(Y) = ", H_y))
#~~~~~~~~~~PART C~~~~~~~~
#Entropy of X conditional on specific y value,
# script to read in raw data and organize it
library(dplyr)
library(readxl)
library(tidyr)
library(stringr)
library(stringi)
library(lubridate)
library(ggmap)
library(ggplot2)
library(caTools)
#setwd('/Users/emmaboudreau/Documents/GitHub/697proj/')
setwd('/Users/samuelesquivel/Documents/GitHub/697project/')
# script to read in raw data and organize it
library(dplyr)
library(readxl)
library(tidyr)
library(stringr)
library(stringi)
library(lubridate)
library(ggmap)
library(ggplot2)
library(caTools)
setwd('/Users/emmaboudreau/Documents/GitHub/697proj/')
#setwd('/Users/samuelesquivel/Documents/GitHub/697project/')
# read in the data-----
data = read.csv('export.csv')
#---- 1 dataframe we could use
data2 = select(data,-c(dist_dirc_exit, age, max_injr_svrty_cl,
numb_fatal_injr, numb_nonfatal_injr,injy_stat_descr,
vehc_unit_numb,crash_status,max_injr_svrty_vl, pers_numb))%>%
filter(!is.na(speed_limit))%>% #filter out anything without speed limit
rename("severity" = "crash_severity_descr")%>% #changed column name
rename("weather" = "weath_cond_descr")%>%
mutate(severity=ifelse(severity=="Property damage only (none injured)",0,
ifelse(severity=="Non-fatal injury",1,ifelse(severity=="Fatal injury",2,3)
)
)
)%>%
filter(severity!="3")%>% #remove any unreported or unknown severity levels
filter(severity!="2")%>% #remove fatal injuries
drop_na()%>% #drop any row with NA
mutate(weather = ifelse(weather =="Clear/Clear","Clear",ifelse(weather == "Rain/Rain","Rain",
ifelse(weather=="Not Reported","Unknown",ifelse(weather=="Snow/Snow","Snow",
ifelse(weather=="Cloudy/Rain","Rain",ifelse(weather=="Clear/Cloudy", "Cloudy",
ifelse(weather=="Snow/Cloudy","Snow",ifelse(weather=="Clear/Blowing sand, snow","Snow",
ifelse(weather=="Rain/Sleet, hail (freezing rain or drizzle)","Rain", ifelse(weather=="Snow/Blowing sand, snow", "Snow",
ifelse(weather=="Clear/Rain","Rain",ifelse(weather=="Cloudy/Cloudy","Cloudy",
ifelse(weather=="Rain/Cloudy","Rain",ifelse(weather=="Rain/Severe crosswinds","Rain",
ifelse(weather=="Snow/Sleet, hail (freezing rain or drizzle)", "Snow",weather)))))))))))
)))))%>% #concatenating weather conditions
mutate(weather=ifelse(weather=="Clear",0,
ifelse(weather=="Cloudy",1,ifelse(weather=="Snow",2,
ifelse(weather=="Rain",3,
ifelse(weather=="Unknown",5,6)
)
)
)
)
)%>% #creating numerical code for different weather conditions
#filter(weather!="5")
filter(weather!="5")%>% #filtering out any unknown or other weather descriptions that are not frequently used/ambiguous
filter(weather!="6")
WS<-as.Date("12/15/2018", format=  "%m/%d/%Y") #winter solstice
SE<-as.Date("03/15/2018", format=  "%m/%d/%Y") #spring equinox
SS<-as.Date("06/15/2018", format=  "%m/%d/%Y") #summer solstice
FE<-as.Date("09/15/2018", format=  "%m/%d/%Y") #fall equinox
#seasons code: winter = 0, spring = 1, summer = 2, fall = 3
data3 = data2%>%
rename("date"="crash_date")%>%
mutate(date = as.Date(date,format= "%m/%d/%Y"))%>%
mutate(season = ifelse(date>=WS | date<SE, "0", ifelse(date>=SE & date< SS, "1",
ifelse(date>=SS&date< FE, "2", "3"))))
###REGARDING TIME###
#step 1
#convert existing date and time to standard POSIX format
data3 <- data3 %>%
mutate(crash_time_2 = str_replace(crash_time_2, "\\s(AM|PM)", " \\1"),  # Remove the space before AM/PM
crash_time_2 = as.POSIXct(crash_time_2, format = "%I:%M %p"),  # Convert to POSIXct format
crash_date = as.Date(date))  # Convert 'date' to Date format
data3 <- data3 %>%
mutate(crash_date_time_standard = as.POSIXct(paste(crash_date, format(crash_time_2, "%H:%M:%S")), format = "%Y-%m-%d %H:%M:%S"))
#step 2
#drop the excess columns we don't need anymore and make new polished data frame
data4 <- data3 %>%
select(-crash_date, -date, -crash_time_2,-crash_numb,-city_town_name)
#drop_na2()%>% #drop any row with NA
#step 3
#do some analysis on the timing of events
#extract the hour from the crash_date_time_standard column
data4 <- data4 %>%
mutate(hour = hour(crash_date_time_standard))
#calculate the crash count for each hour
crash_count <- data4 %>%
count(hour)
#plot the crash count by hour
plot(crash_count$hour, crash_count$n, type = "l", xlab = "Hour of Day", ylab = "Crash Count", main = "Crash Count by Hour")
###REGARDING LOCATION###
# Load required libraries
library(ggplot2)
library(ggmap)
#set the latitude and longitude boundaries for Boston area
boston_bounds <- c(left = -71.1912, bottom = 42.2279, right = -70.8085, top = 42.3974)
#get the map background using ggmap and specify the map type
boston_map <- get_stamenmap(boston_bounds, maptype = "toner-lite")
#plot the map of Boston
ggmap(boston_map) +
#add points representing crash locations
geom_point(data = data4, aes(x = lon, y = lat), color = "red", alpha = 0.5) +
#adjust the transparency and color of the points
guides(alpha = FALSE) +
labs(title = "Crashes in Boston, MA") +
theme(plot.title = element_text(hjust = 0.5))
#---- logistic regression
data4 <- na.omit(data4)
# Loading caret library
library(caret)
# Splitting the data into train and test
index <- createDataPartition(data4$severity, p = .70, list = FALSE)
train <- data4[index, ]
test <- data4[-index, ]
# Training the model
logistic_model <- glm(severity ~ ., family = binomial(), train)
# Checking the model
summary(logistic_model)
pred_prob_lg <- predict(logistic_model, test, type = "response")
train$pred_class <- ifelse(logistic_model$fitted.values>=0.5, "Yes", "No")
# Generating the classification table
ctab_train <- table(train$severity, train$pred_class)
ctab_train
# Converting from probability to actual output
test$pred_class <- ifelse(pred_prob_lg >= 0.5, "Yes", "No")
# Generating the classification table
ctab_test <- table(test$severity, test$pred_class)
ctab_test
#Accuracy = (TP + TN)/(TN + FP + FN + TP)
# Accuracy in Training dataset
accuracy_train <- sum(diag(ctab_train))/sum(ctab_train)*100
accuracy_train
# Accuracy in Test dataset
accuracy_test <- sum(diag(ctab_test))/sum(ctab_test)*100
accuracy_test
Recall <- (ctab_train[2, 2]/sum(ctab_train[2, ]))*100
Recall
TNR <- (ctab_train[1, 1]/sum(ctab_train[1, ]))*100
TNR
Precision <- (ctab_train[2, 2]/sum(ctab_train[, 2]))*100
Precision
F_Score <- (2 * Precision * Recall / (Precision + Recall))/100
F_Score
#library(pROC)
#roc <- roc(train$Class, logistic_model$fitted.values)
#auc(roc)
#---- SVM
library(e1071)
svm_model <- svm(formula = severity ~ ., kernel = "radial", data = train)
y_pred = predict(svm_model, newdata = test)
y_pred = ifelse(y_pred>=.5, "1","0")
a = 100*mean(y_pred==test[,1])
accuracy <- sum(y_pred == test$severity) / nrow(test)
print(paste("Accuracy:", accuracy))
g = plot(data4$season)
g
g = plot(data4$season)
g
View(data4)
pl = ggplot(data = data4, aes(x=season))
pl
View(pl)
ggplot(data = data4, aes(x=season, fill=severity)) +
geom_bar(stat = "identity")+
geom_text(aes(y=label_ypos))
ggplot(data = data4, aes(x=season, fill=severity)) +
geom_bar(stat = "identity")+ theme_minimal()
ggplot(data = data4, aes(x=seaso)) +
geom_bar()
ggplot(data = data4, aes(x=season)) +
geom_bar()
ggplot(data = data4, aes(x=season)) +
geom_bar()
pl =ggplot(data = data4, aes(x=season)) +
geom_bar()
pl
pl
pl =ggplot(data = data4, aes(x=season)) +
geom_bar()
pl
pl =ggplot(data = data4, aes(x=season)) +
geom_bar(stat = "identity")
pl
season_counts <- data4 %>%
group_by(season, severity) %>%
summarise(count = n()) %>%
ungroup()
# Map season codes to season labels
season_counts$season <- case_when(
season_counts$season == "0" ~ "Winter",
season_counts$season == "1" ~ "Spring",
season_counts$season == "2" ~ "Summer",
season_counts$season == "3" ~ "Fall"
)
# Plot the bar plot
ggplot(season_counts, aes(x = season, y = count, fill = as.factor(severity))) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "Season", y = "Count", fill = "Severity") +
scale_fill_manual(values = c("0" = "blue", "1" = "red"),
labels = c("Non-Injury", "Injury")) +
theme_minimal()
# Plot the bar plot
ggplot(season_counts, aes(x = season, y = count, fill = as.factor(severity))) +
geom_bar(stat = "identity") +
labs(x = "Season", y = "Count", fill = "Severity") +
scale_fill_manual(values = c("0" = "blue", "1" = "red"),
labels = c("Non-Injury", "Injury")) +
theme_minimal()
ggplot(season_counts, aes(x = season, y = count, fill = as.factor(severity))) +
geom_bar(stat = "identity") +
labs(x = "Season", y = "Count", fill = "Severity") +
scale_fill_brewer(palette = "Paired",
labels = c("Non-Injury", "Injury")) +
theme_minimal()
# Plot the bar plot
ggplot(season_counts, aes(x = season, y = count, fill = as.factor(severity))) +
geom_bar(stat = "identity") +
labs(x = "Season", y = "Count", fill = "Severity") +
geom_text(aes(y=label_ypos,label=count),vjust=1.6,
size=3.5) +
scale_fill_brewer(palette = "Paired",
labels = c("Non-Injury", "Injury")) +
theme_minimal()
# Plot the bar plot
ggplot(season_counts, aes(x = season, y = count, fill = as.factor(severity))) +
geom_bar(stat = "identity") +
labs(x = "Season", y = "Count", fill = "Severity") +
geom_text(aes(label=count),vjust=1.6,
size=3.5) +
scale_fill_brewer(palette = "Paired",
labels = c("Non-Injury", "Injury")) +
theme_minimal()
# Plot the bar plot
ggplot(season_counts, aes(x = season, y = count, fill = as.factor(severity))) +
geom_bar(stat = "identity") +
labs(x = "Season", y = "Count", fill = "Severity") +
geom_text(aes(label=count),vjust=1.6,
size=3.5, color = "grey") +
scale_fill_brewer(palette = "Paired",
labels = c("Non-Injury", "Injury")) +
theme_minimal()
# Plot the bar plot
ggplot(season_counts, aes(x = season, y = count, fill = as.factor(severity))) +
geom_bar(stat = "identity") +
labs(x = "Season", y = "Count", fill = "Severity") +
geom_text(aes(label=count),vjust=1.6,
size=3.5, color = "white") +
scale_fill_brewer(palette = "Paired",
labels = c("Non-Injury", "Injury")) +
theme_minimal()
# Plot the bar plot
ggplot(season_counts, aes(x = season, y = count, fill = as.factor(severity))) +
geom_bar(stat = "identity") +
labs(x = "Season", y = "Count", title= "Severity by Season", color = "grey", fill = "Severity") +
geom_text(aes(label=count),vjust=1.6,
size=3.5, color = "white") +
scale_fill_brewer(palette = "Paired",
labels = c("Non-Injury", "Injury")) +
theme_minimal()
# Plot the bar plot
ggplot(season_counts, aes(x = season, y = count, fill = as.factor(severity))) +
geom_bar(stat = "identity") +
labs(x = "Season", y = "Count", color = "grey", fill = "Severity") +
geom_text(aes(label=count),vjust=1.6,
size=3.5, color = "white") +
scale_fill_brewer(palette = "Paired",
labels = c("Non-Injury", "Injury")) +
theme_minimal()+ ggtitle("Severity by Season")
source("~/Documents/GitHub/697proj/ugh.R", echo=TRUE)
source("~/Documents/GitHub/697proj/ugh.R", echo=TRUE)
season_counts <- data4 %>%
group_by(season, severity) %>%
summarise(count = n()) %>%
ungroup()
# Map season codes to season labels
season_counts$season <- case_when(
season_counts$season == "0" ~ "Winter",
season_counts$season == "1" ~ "Spring",
season_counts$season == "2" ~ "Summer",
season_counts$season == "3" ~ "Fall"
)
# Plot the bar plot
ggplot(season_counts, aes(x = season, y = count, fill = as.factor(severity))) +
geom_bar(stat = "identity") +
labs(x = "Season", y = "Count", color = "grey", fill = "Severity") +
geom_text(aes(label=count),vjust=1.6,
size=3.5, color = "white") +
scale_fill_brewer(palette = "Paired",
labels = c("Non-Injury", "Injury")) +
theme_minimal()
#injury (severity 1) and non-injury (severity 0) in each weather condition
weather_counts <- data4 %>%
group_by(weather, severity) %>%
summarise(count = n()) %>%
ungroup()
#weather code
weather_counts$weather <- case_when(
weather_counts$weather == 0 ~ "Clear",
weather_counts$weather == 1 ~ "Cloudy",
weather_counts$weather == 2 ~ "Rain",
weather_counts$weather == 3 ~ "Snow"
)
#bar plot
ggplot(weather_counts, aes(x = weather, y = count, fill = as.factor(severity))) +
geom_bar(stat = "identity") +
labs(x = "Weather Condition", y = "Count",color = "grey", fill = "Severity") +
geom_text(aes(label=count),vjust=1.6,
size=3.5, color = "white") +
scale_fill_brewer(palette = "Paired",
labels = c("Non-Injury", "Injury")) +
theme_minimal()
summary(logistic_model)
