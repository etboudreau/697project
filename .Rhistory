plot(x,y)
plot(nation,national_mean)
plot(nation,national_mean)
AcceptData <- read.table(text="
Mean.Rank Sentence.Type
1       2.5       An+Sp+a
2       2.6      An+Nsp+a
3       2.1       An+Sp-a
4       3.1      An+Nsp-a
5       2.4       In+Sp+a
6       1.7      In+Nsp+a
7       3.1       In+Sp-a
8       3.0      In+Nsp-a", stringsAsFactors=FALSE)
plot(Mean.Rank~factor(Sentence.Type), AcceptData, las=2,
xlab="", main="Mean Acceptability Ranking per Sentence")
plot(nation~factor(success), AcceptData, las=2,
xlab="", main="Mean Acceptability Ranking per Sentence")
#clear the workspace
rm(list=ls())
#call the data
load("/Users/samuelesquivel/Desktop/UMass Academic /4- SENIOR YEAR/CICS109/Portfolios/everest_day2.rdata")
########Portfolio begin########
#How many expeditions were there? How many were successful?
#How many total?
length(success)
#How many were a success?
success_success <- success[success > 0]
length(success_success)
#How many were a failure?
success_failure <- success[success < 1]
length(success_failure)
#Does success vary by country?
#Country frequency of success and means,
#Part 1
#pulling out nation and success condition from data
nation_x <- nation[1:99]
success_y <- success[1:99]
#putting them together for construction of data frame
cbind(nation_x, success_y)
#data frame that has the nation and logical of success
nation_success <- data.frame(cbind(nation_x, success_y))
#Part 2
#turns success logical into an integer
success_integer <- as.integer(success)
#makes that success integer pair with the nation in a data frame
national_success <- data.frame(Nation = nation, Success = success_integer)
#takes that data frame and gives us success mean
national_mean <- aggregate(success ~ nation, data = national_success, mean)
#this tells us if the country has been successful or not super successful in their expeditions
#if the mean is 1.00 then its all been success, else a 0.0 means all expeditions failed
print(national_mean)
#Relationships involving number of climbers
#this comparison allows us to see the number of people in expedition and if they succeed or not
pplandsuccess <- cbind(nation, totmembers, success)
print(pplandsuccess)
plot(nation,national_mean)
y = c(national_mean)
mean(national_success
)
national_success
y <- aggregate(data = national_success, mean)
y <- aggregate(success ~ success, data = national_success, mean)
y
national_mean <- aggregate(nation ~ success, data = national_success, mean)
national_mean <- aggregate(success ~ nation, data = national_success, mode)
y
y
plot(nation_success,national_mean)
plot(tothired)
plot(totmembers)
tothired
plot(pplandsuccess)
plot(success)
plot(success_integer)
plot(success,nation)
plot(success)
sort(national_mean)
sort(nation)
sum(nation == "USA")
sorted_nation <- sort(nation)
ARG <- sorted_nation[1:2]
ARG
sort(national_mean)
plot(success)
plot(totmembers)
plot(tothired)
#clear the workspace
rm(list=ls())
#call the data
load("/Users/samuelesquivel/Desktop/UMass Academic /4- SENIOR YEAR/CICS109/Portfolios/everest_day2.rdata")
########Portfolio begin########
#How many expeditions were there? How many were successful?
#How many total?
length(success)
#How many were a success?
success_success <- success[success > 0]
length(success_success)
#How many were a failure?
success_failure <- success[success < 1]
length(success_failure)
#Does success vary by country?
#Country frequency of success and means,
#Part 1
#pulling out nation and success condition from data
nation_x <- nation[1:99]
success_y <- success[1:99]
#putting them together for construction of data frame
cbind(nation_x, success_y)
#data frame that has the nation and logical of success
nation_success <- data.frame(cbind(nation_x, success_y))
#Part 2
#turns success logical into an integer
success_integer <- as.integer(success)
#makes that success integer pair with the nation in a data frame
national_success <- data.frame(Nation = nation, Success = success_integer)
#takes that data frame and gives us success mean
national_mean <- aggregate(success ~ nation, data = national_success, mean)
#this tells us if the country has been successful or not super successful in their expeditions
#if the mean is 1.00 then its all been success, else a 0.0 means all expeditions failed
print(national_mean)
#Relationships involving number of climbers
#this comparison allows us to see the number of people in expedition and if they succeed or not
pplandsuccess <- cbind(nation, totmembers, success)
print(pplandsuccess)
#plots
#I was unable to plot what I was thinking of plotting- country by success rate, country by avg. members
#The issue is that I was unable to resolve was combining the character with other vectors in the set
#I ideally would have joined the 2 in a data frame or matrix to run stats on them and compare the results
#However I did not want to get errors back so I took out a lot of what I did as it didn't make sense!
#Since I could not figure the syntax, I brainstormed other options to get closer but not exactly what I want
#If I could have sorted/filtered out parts of the vector BUT maintained the character that describes the country, this
#would have also been ideal.
plot(totmembers)
plot(tothired)
plot(success)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
# script to read in raw data and organize it
library(dplyr)
library(readxl)
library(tidyr)
library(stringr)
library(stringi)
library(lubridate)
#install.packages("ggmap")
library(ggmap)
#install.packages("ggplot2")
library(ggplot2)
#install.packages("caTools")
library(caTools)
#setwd('/Users/emmaboudreau/Documents/GitHub/697proj/')
setwd('/Users/samuelesquivel/Documents/GitHub/697project/')
# read in the data-----
data = read.csv('export.csv')
#Model building
#---- 1 dataframe we could use
data2 = select(data,-c(dist_dirc_exit, age, max_injr_svrty_cl,
numb_fatal_injr, numb_nonfatal_injr,injy_stat_descr,
vehc_unit_numb,crash_status,max_injr_svrty_vl, pers_numb))%>%
filter(!is.na(speed_limit))%>% #filter out anything without speed limit
rename("severity" = "crash_severity_descr")%>% #changed column name
rename("weather" = "weath_cond_descr")%>%
mutate(severity=ifelse(severity=="Property damage only (none injured)",0,
ifelse(severity=="Non-fatal injury",1,ifelse(severity=="Fatal injury",2,3)
)
)
)%>%
filter(severity!="3")%>% #remove any unreported or unknown severity levels
filter(severity!="2")%>% #remove fatal injuries
drop_na()%>% #drop any row with NA
mutate(weather = ifelse(weather =="Clear/Clear","Clear",ifelse(weather == "Rain/Rain","Rain",
ifelse(weather=="Not Reported","Unknown",ifelse(weather=="Snow/Snow","Snow",
ifelse(weather=="Cloudy/Rain","Rain",ifelse(weather=="Clear/Cloudy", "Cloudy",
ifelse(weather=="Snow/Cloudy","Snow",ifelse(weather=="Clear/Blowing sand, snow","Snow",
ifelse(weather=="Rain/Sleet, hail (freezing rain or drizzle)","Rain", ifelse(weather=="Snow/Blowing sand, snow", "Snow",
ifelse(weather=="Clear/Rain","Rain",ifelse(weather=="Cloudy/Cloudy","Cloudy",
ifelse(weather=="Rain/Cloudy","Rain",ifelse(weather=="Rain/Severe crosswinds","Rain",
ifelse(weather=="Snow/Sleet, hail (freezing rain or drizzle)", "Snow",weather)))))))))))
)))))%>% #concatenating weather conditions
mutate(weather=ifelse(weather=="Clear",0,
ifelse(weather=="Cloudy",1,ifelse(weather=="Snow",2,
ifelse(weather=="Rain",3,
ifelse(weather=="Unknown",5,6)
)
)
)
)
)%>% #creating numerical code for different weather conditions
#filter(weather!="5")
filter(weather!="5")%>% #filtering out any unknown or other weather descriptions that are not frequently used/ambiguous
filter(weather!="6")
WS<-as.Date("12/15/2018", format=  "%m/%d/%Y") #winter solstice
SE<-as.Date("03/15/2018", format=  "%m/%d/%Y") #spring equinox
SS<-as.Date("06/15/2018", format=  "%m/%d/%Y") #summer solstice
FE<-as.Date("09/15/2018", format=  "%m/%d/%Y") #fall equinox
#seasons code: winter = 0, spring = 1, summer = 2, fall = 3
data3 = data2%>%
rename("date"="crash_date")%>%
mutate(date = as.Date(date,format= "%m/%d/%Y"))%>%
mutate(season = ifelse(date>=WS | date<SE, "0", ifelse(date>=SE & date< SS, "1",
ifelse(date>=SS&date< FE, "2", "3"))))
###REGARDING TIME###
#step 1
#convert existing date and time to standard POSIX format
data3 <- data3 %>%
mutate(crash_time_2 = str_replace(crash_time_2, "\\s(AM|PM)", " \\1"),  # Remove the space before AM/PM
crash_time_2 = as.POSIXct(crash_time_2, format = "%I:%M %p"),  # Convert to POSIXct format
crash_date = as.Date(date))  # Convert 'date' to Date format
data3 <- data3 %>%
mutate(crash_date_time_standard = as.POSIXct(paste(crash_date, format(crash_time_2, "%H:%M:%S")), format = "%Y-%m-%d %H:%M:%S"))
#step 2
#drop the excess columns we don't need anymore and make new polished data frame
data4 <- data3 %>%
select(-crash_date, -date, -crash_time_2)
#drop_na2()%>% #drop any row with NA
#step 3
#do some analysis on the timing of events
#extract the hour from the crash_date_time_standard column
data4 <- data4 %>%
mutate(hour = hour(crash_date_time_standard))
#calculate the crash count for each hour
crash_count <- data4 %>%
count(hour)
#plot the crash count by hour
plot(crash_count$hour, crash_count$n, type = "l", xlab = "Hour of Day", ylab = "Crash Count", main = "Crash Count by Hour")
###REGARDING LOCATION###
# Load required libraries
library(ggplot2)
library(ggmap)
#set the latitude and longitude boundaries for Boston area
boston_bounds <- c(left = -71.1912, bottom = 42.2279, right = -70.8085, top = 42.3974)
#get the map background using ggmap and specify the map type
boston_map <- get_stamenmap(boston_bounds, maptype = "toner-lite")
#plot the map of Boston
ggmap(boston_map) +
#add points representing crash locations
geom_point(data = data4, aes(x = lon, y = lat), color = "red", alpha = 0.5) +
#adjust the transparency and color of the points
guides(alpha = FALSE) +
labs(title = "Crashes in Boston, MA") +
theme(plot.title = element_text(hjust = 0.5))
###SVM Construction###
# Load required libraries
library(dplyr)
library(e1071)  # For SVM
library(caret)  # For model evaluation
# Specify the column names for input variables and the target variable
input_cols <- c("lat", "lon", "numb_vehc", "speed_limit", "driver_age", "total_occpt_in_vehc", "season", "weather")
target_col <- "severity"
# Split the data into training and testing sets
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(data4), 0.7 * nrow(data4))  # 70% for training
train_data <- data4[train_indices, ]
test_data <- data4[-train_indices, ]
# Create the SVM model
svm_model <- svm(formula = as.formula(paste(target_col, "~", paste(input_cols, collapse = "+"))),
data = train_data)
# Make predictions on the test data
predictions <- predict(svm_model, newdata = test_data)
# Evaluate the model
accuracy <- sum(predictions == test_data$severity) / nrow(test_data)
print(paste("Accuracy:", accuracy))
svm_model
###SVM Construction###
# Load required libraries
library(dplyr)
library(e1071)  # For SVM
library(caret)  # For model evaluation
# Specify the column names for input variables and the target variable
input_cols <- c("lat", "lon", "numb_vehc", "speed_limit", "driver_age", "total_occpt_in_vehc", "season", "weather")
target_col <- "severity"
# Split the data into training and testing sets
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(data4), 0.7 * nrow(data4))  # 70% for training
train_data <- data4[train_indices, ]
test_data <- data4[-train_indices, ]
# Create the SVM model
svm_model <- svm(formula = as.formula(paste(target_col, "~", paste(input_cols, collapse = "+"))),
data = train_data)
# Make predictions on the test data
predictions <- predict(svm_model, newdata = test_data)
# Evaluate the model
accuracy <- sum(predictions == test_data$severity) / nrow(test_data)
print(paste("Accuracy:", accuracy))
# Load required libraries
library(dplyr)
library(e1071)  # For SVM
library(caret)  # For model evaluation
# Specify the column names for input variables and the target variable
input_cols <- c("lat", "lon", "numb_vehc", "speed_limit", "driver_age", "total_occpt_in_vehc", "season", "weather")
target_col <- "severity"
# Split the data into training and testing sets
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(data4), 0.7 * nrow(data4))  # 70% for training
train_data <- data4[train_indices, ]
test_data <- data4[-train_indices, ]
# Preprocess the input features (e.g., scale/normalize)
train_data[input_cols] <- scale(train_data[input_cols])
test_data[input_cols] <- scale(test_data[input_cols])
# Load required libraries
library(dplyr)
library(e1071)  # For SVM
library(caret)  # For model evaluation
# Specify the column names for input variables and the target variable
input_cols <- c("lat", "lon", "numb_vehc", "speed_limit", "driver_age", "total_occpt_in_vehc", "season", "weather")
target_col <- "severity"
# Split the data into training and testing sets
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(data4), 0.7 * nrow(data4))  # 70% for training
train_data <- data4[train_indices, ]
test_data <- data4[-train_indices, ]
# Check if input columns are numeric
if (!all(sapply(train_data[, input_cols], is.numeric))) {
stop("Input columns must be numeric.")
}
#colnames(data4)
colnames(data3)
colnames(data4)
str(train_data)
colnames(data4)
data5 <- data4 %>%
select(-c(crash_numb, city_town_name, season))
# Print the updated data frame 'data5'
print(data5)
# Load required libraries
library(dplyr)
library(e1071)  # For SVM
library(caret)  # For model evaluation
# Specify the column names for input variables and the target variable
input_cols <- c("lat", "lon", "numb_vehc", "speed_limit", "driver_age", "total_occpt_in_vehc", "season", "weather")
target_col <- "severity"
# Split the data into training and testing sets
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(data5), 0.7 * nrow(data5))  # 70% for training
train_data <- data5[train_indices, ]
test_data <- data5[-train_indices, ]
# Check if input columns are numeric
if (!all(sapply(train_data[, input_cols], is.numeric))) {
stop("Input columns must be numeric.")
}
######################
###SVM Construction###
# Load required libraries
library(dplyr)
library(e1071)  # For SVM
library(caret)  # For model evaluation
# Specify the column names for input variables and the target variable
input_cols <- c("lat", "lon", "numb_vehc", "speed_limit", "driver_age", "total_occpt_in_vehc", "season", "weather")
target_col <- "severity"
# Split the data into training and testing sets
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(data5), 0.7 * nrow(data5))  # 70% for training
train_data <- data5[train_indices, ]
test_data <- data5[-train_indices, ]
# Create the SVM model
svm_model <- svm(formula = as.formula(paste(target_col, "~", paste(input_cols, collapse = "+"))),
data = train_data)
######################
###SVM Construction###
# Load required libraries
library(dplyr)
library(e1071)  # For SVM
library(caret)  # For model evaluation
# Specify the column names for input variables and the target variable
input_cols <- c("lat", "lon", "numb_vehc", "speed_limit", "driver_age", "total_occpt_in_vehc", "weather")
target_col <- "severity"
# Split the data into training and testing sets
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(data5), 0.7 * nrow(data5))  # 70% for training
train_data <- data5[train_indices, ]
test_data <- data5[-train_indices, ]
# Create the SVM model
svm_model <- svm(formula = as.formula(paste(target_col, "~", paste(input_cols, collapse = "+"))),
data = train_data)
# Make predictions on the test data
predictions <- predict(svm_model, newdata = test_data)
# Evaluate the model
accuracy <- sum(predictions == test_data$severity) / nrow(test_data)
print(paste("Accuracy:", accuracy))
####################
svm_model
# Specify the column names for input variables and the target variable
input_cols <- c("lat", "lon", "numb_vehc", "speed_limit", "driver_age", "total_occpt_in_vehc", "weather")
target_col <- "severity"
na.omit
# Split the data into training and testing sets
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(data5), 0.7 * nrow(data5))  # 70% for training
train_data <- data5[train_indices, ]
test_data <- data5[-train_indices, ]
# Create the SVM model
svm_model <- svm(formula = as.formula(paste(target_col, "~", paste(input_cols, collapse = "+"))),
data = train_data)
# Make predictions on the test data
predictions <- predict(svm_model, newdata = test_data)
# Evaluate the model
accuracy <- sum(predictions == test_data$severity) / nrow(test_data)
print(paste("Accuracy:", accuracy))
train_data$numb_vehc <- as.numeric(train_data$numb_vehc)
View(train_data)
train_data$numb_vehc <- as.numeric(train_data$numb_vehc)
train_data$speed_limit <- as.numeric(train_data$speed_limit)
train_data$driver_age <- as.numeric(train_data$driver_age)
train_data$total_occpt_in_vehc <- as.numeric(train_data$total_occpt_in_vehc)
str(train_data)
# Assuming 'data4' is the existing data frame
# Create 'data5' by removing columns 'crash_numb', 'city_town_name', and 'season'
data5 <- data4 %>%
select(-c(crash_numb, city_town_name, season))
# Print the updated data frame 'data5'
print(data5)
# Load required libraries
library(dplyr)
library(e1071)  # For SVM
library(caret)  # For model evaluation
# Specify the column names for input variables and the target variable
input_cols <- c("lat", "lon", "numb_vehc", "speed_limit", "driver_age", "total_occpt_in_vehc", "season", "weather")
target_col <- "severity"
# Split the data into training and testing sets
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(data5), 0.7 * nrow(data5))  # 70% for training
train_data <- data5[train_indices, ]
test_data <- data5[-train_indices, ]
#make everything numeric
train_data$numb_vehc <- as.numeric(train_data$numb_vehc)
train_data$speed_limit <- as.numeric(train_data$speed_limit)
train_data$driver_age <- as.numeric(train_data$driver_age)
train_data$total_occpt_in_vehc <- as.numeric(train_data$total_occpt_in_vehc)
# Check if input columns are numeric
if (!all(sapply(train_data[, input_cols], is.numeric))) {
stop("Input columns must be numeric.")
}
# Assuming 'data4' is the existing data frame
# Create 'data5' by removing columns 'crash_numb', 'city_town_name', and 'season'
data5 <- data4 %>%
select(-c(crash_numb, city_town_name, season))
# Print the updated data frame 'data5'
print(data5)
# Load required libraries
library(dplyr)
library(e1071)  # For SVM
library(caret)  # For model evaluation
# Specify the column names for input variables and the target variable
input_cols <- c("lat", "lon", "numb_vehc", "speed_limit", "driver_age", "total_occpt_in_vehc", "season", "weather")
target_col <- "severity"
# Split the data into training and testing sets
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(data5), 0.7 * nrow(data5))  # 70% for training
train_data <- data5[train_indices, ]
test_data <- data5[-train_indices, ]
#make everything numeric
train_data$numb_vehc <- as.numeric(train_data$numb_vehc)
train_data$speed_limit <- as.numeric(train_data$speed_limit)
train_data$driver_age <- as.numeric(train_data$driver_age)
train_data$total_occpt_in_vehc <- as.numeric(train_data$total_occpt_in_vehc)
# Check if input columns are numeric
#if (!all(sapply(train_data[, input_cols], is.numeric))) {
#stop("Input columns must be numeric.")
#}
na.omit
# Create the SVM model
svm_model <- train(
x = train_data[, input_cols],
y = train_data[[target_col]],
method = "svmRadial",  # Radial kernel for SVM
trControl = trainControl(method = "cv", number = 5),  # 5-fold cross-validation
tuneLength = 5,  # Number of hyperparameter combinations to try
preProcess = c("center", "scale")  # Feature scaling
)
# Assuming 'data4' is the existing data frame
# Create 'data5' by removing columns 'crash_numb', 'city_town_name', and 'season'
data5 <- data4 %>%
select(-c(crash_numb, city_town_name, season))
# Print the updated data frame 'data5'
print(data5)
# Load required libraries
library(dplyr)
library(e1071)  # For SVM
library(caret)  # For model evaluation
# Specify the column names for input variables and the target variable
input_cols <- c("lat", "lon", "numb_vehc", "speed_limit", "driver_age", "total_occpt_in_vehc", "weather")
target_col <- "severity"
# Split the data into training and testing sets
set.seed(123)  # For reproducibility
train_indices <- sample(1:nrow(data5), 0.7 * nrow(data5))  # 70% for training
train_data <- data5[train_indices, ]
test_data <- data5[-train_indices, ]
#make everything numeric
train_data$numb_vehc <- as.numeric(train_data$numb_vehc)
train_data$speed_limit <- as.numeric(train_data$speed_limit)
train_data$driver_age <- as.numeric(train_data$driver_age)
train_data$total_occpt_in_vehc <- as.numeric(train_data$total_occpt_in_vehc)
# Check if input columns are numeric
#if (!all(sapply(train_data[, input_cols], is.numeric))) {
#stop("Input columns must be numeric.")
#}
na.omit
# Create the SVM model
svm_model <- train(
x = train_data[, input_cols],
y = train_data[[target_col]],
method = "svmRadial",  # Radial kernel for SVM
trControl = trainControl(method = "cv", number = 5),  # 5-fold cross-validation
tuneLength = 5,  # Number of hyperparameter combinations to try
preProcess = c("center", "scale")  # Feature scaling
)
# Make predictions on the test data
predictions <- predict(svm_model, newdata = test_data[, input_cols])
# Evaluate the model
accuracy <- sum(predictions == test_data[[target_col]]) / nrow(test_data)
print(paste("Accuracy:", accuracy))
