discharge <- readNWISuv(siteNumbers = site,
parameterCd = "00060",
startDate = "2011-11-01",
endDate = "2015-01-01")
discharge <- renameNWISColumns(discharge)%>%
mutate(flow_Inst_2 = Flow_Inst*.0283168)
precip <- readNWISuv(siteNumbers = site,
parameterCd = "00045",
startDate = "2022-05-17",
endDate = "2022-10-01")
precip <-renameNWISColumns(precip)
#names(precip)[4] <- 'precip'
p1
source("~/.active-rstudio-document", echo=TRUE)
View(discharge)
p1
source("~/.active-rstudio-document", echo=TRUE)
p1
discharge <- readNWISuv(siteNumbers = site,
parameterCd = "00060",
startDate = "2013-10-01",
endDate = "2015-01-01")
discharge <- renameNWISColumns(discharge)%>%
mutate(flow_Inst_2 = Flow_Inst*.0283168)
precip <- readNWISuv(siteNumbers = site,
parameterCd = "00045",
startDate = "2022-05-17",
endDate = "2022-10-01")
precip <-renameNWISColumns(precip)
#names(precip)[4] <- 'precip'
p1
## download some example data
site <- "09010500"
discharge <- readNWISuv(siteNumbers = site,
parameterCd = "00060",
startDate = "2013-06-01",
endDate = "2015-01-01")
discharge <- renameNWISColumns(discharge)%>%
mutate(flow_Inst_2 = Flow_Inst*.0283168)
p`1`
p1
site <- "09010500"
discharge <- readNWISuv(siteNumbers = site,
parameterCd = "00060",
startDate = "2013-03-01",
endDate = "2015-01-01")
discharge <- renameNWISColumns(discharge)%>%
mutate(flow_Inst_2 = Flow_Inst*.0283168)
precip <- readNWISuv(siteNumbers = site,
parameterCd = "00045",
startDate = "2022-05-17",
endDate = "2022-10-01")
precip <-renameNWISColumns(precip)
p1
## download some example data
site <- "09010500"
discharge <- readNWISuv(siteNumbers = site,
parameterCd = "00060",
startDate = "2013-01-07",
endDate = "2015-01-01")
discharge <- renameNWISColumns(discharge)%>%
mutate(flow_Inst_2 = Flow_Inst*.0283168)
p1
View(discharge)
source("~/.active-rstudio-document", echo=TRUE)
p1
source("~/.active-rstudio-document", echo=TRUE)
p1
source("~/.active-rstudio-document", echo=TRUE)
p1
source("~/.active-rstudio-document", echo=TRUE)
p1
p1 <- ggplot(joined_data) +
geom_line(aes(dateTime, flow_Inst_2, color = "Discharge")) +
scale_y_continuous(position = "left",
limits = c(0, 35),
expand = c(0,0)) +
scale_color_manual(values = c("steelblue")) +
guides(x = guide_axis(angle = 90)) +
ggtitle("COLORADO RIVER BELOW BAKER GULCH NR GRAND LAKE, CO") +
labs(y = "Discharge [cms]",
x = "Date (10-2013 to 10-2014")
p1
p1 <- ggplot(joined_data) +
geom_line(aes(dateTime, flow_Inst_2, color = "Discharge")) +
scale_y_continuous(position = "left",
limits = c(0, 35),
expand = c(0,0)) +
scale_color_manual(values = c("steelblue")) +
guides(x = guide_axis(angle = 90)) +
ggtitle("COLORADO RIVER BELOW BAKER GULCH NR GRAND LAKE, CO") +
labs(y = "Discharge [cms]",
x = "Date (10-2013 to 10-2014)")
p1
X = c(.1,.2,.1,.4,.5,.1,.1,.1,.2,.1) #weighing coefficient
d = c(1,4,4,7,6,7,7,14,15,20) #m
K = 1000/sqrt(9.81*d) #
I = c(100,120,140,150,150,160,130,120,110,100) #m3/s
delt = 1 #day
Q = 100
t = c(1,2,3,4,5,6,7,8,9,10)
i = seq(100:1000, by=100)
X = c(.1,.2,.1,.4,.5,.1,.1,.1,.2,.1) #weighing coefficient
d = c(1,4,4,7,6,7,7,14,15,20) #m
K = 1000/sqrt(9.81*d) #
# I = c(100,120,140,150,150,160,130,120,110,100) #m3/s
delt = 1 #day
Q = 100
t = c(1,2,3,4,5,6,7,8,9,10)
# i = seq(100,1000, by=100)
for (i in 1:9) {
for (j in 1:9) {
C1 = (delt-2*K*X)/(2*K*(1-X)+delt)
C2 = (delt+2*K*X)/(2*K*(1-X)+delt)
C3 = (2*K*(1-X)-delt)/(2*k*(1-X)+delt)
Q[i+1,j+1]=C1[i]*Q[i,j+1]+C2[i]*Q[i,j]+C3[i]Q[i+1,j]
X = c(.1,.2,.1,.4,.5,.1,.1,.1,.2,.1) #weighing coefficient
d = c(1,4,4,7,6,7,7,14,15,20) #m
K = 1000/sqrt(9.81*d) #
# I = c(100,120,140,150,150,160,130,120,110,100) #m3/s
delt = 1 #day
Q = 100
t = c(1,2,3,4,5,6,7,8,9,10)
# i = seq(100,1000, by=100)
for (i in 1:9) {
for (j in 1:9) {
C1 = (delt-2*K*X)/(2*K*(1-X)+delt)
C2 = (delt+2*K*X)/(2*K*(1-X)+delt)
C3 = (2*K*(1-X)-delt)/(2*k*(1-X)+delt)
Q[i+1,j+1]=C1[i]*Q[i,j+1]+C2[i]*Q[i,j]+C3[i]*Q[i+1,j]
}
}
X = c(.1,.2,.1,.4,.5,.1,.1,.1,.2,.1) #weighing coefficient
d = c(1,4,4,7,6,7,7,14,15,20) #m
K = 1000/sqrt(9.81*d) #
I = c(100,120,140,150,150,160,130,120,110,100) #m3/s
delt = 1 #day
Q = 100
t = c(1,2,3,4,5,6,7,8,9,10)
# i = seq(100,1000, by=100)
C1 = (delt-2*K*X)/(2*K*(1-X)+delt)
C2 = (delt+2*K*X)/(2*K*(1-X)+delt)
C3 = (2*K*(1-X)-delt)/(2*k*(1-X)+delt)
X = c(.1,.2,.1,.4,.5,.1,.1,.1,.2,.1) #weighing coefficient
d = c(1,4,4,7,6,7,7,14,15,20) #m
K = 1000/sqrt(9.81*d) #
I = c(100,120,140,150,150,160,130,120,110,100) #m3/s
delt = 1 #day
Q = 100
t = c(1,2,3,4,5,6,7,8,9,10)
# i = seq(100,1000, by=100)
C1 = (delt-2*K*X)/(2*K*(1-X)+delt)
C2 = (delt+2*K*X)/(2*K*(1-X)+delt)
C3 = (2*K*(1-X)-delt)/(2*K*(1-X)+delt)
Q = matrix(100, nrow=10, ncol=10)
Q[,1]= I
for (i in 1:9) {
for (j in 1:9) {
Q[i+1,j+1]=C1[i]*Q[i,j+1]+C2[i]*Q[i,j]+C3[i]*Q[i+1,j]
}
}
Q
X = c(.1,.2,.1,.4,.5,.1,.1,.1,.2,.1) #weighing coefficient
d = c(1,4,4,7,6,7,7,14,15,20) #m
K = 100/sqrt(9.81*d) #
I = c(100,120,140,150,150,160,130,120,110,100) #m3/s
delt = 1 #day
Q = 100
t = c(1,2,3,4,5,6,7,8,9,10)
# i = seq(100,1000, by=100)
C1 = (delt-2*K*X)/(2*K*(1-X)+delt)
C2 = (delt+2*K*X)/(2*K*(1-X)+delt)
C3 = (2*K*(1-X)-delt)/(2*K*(1-X)+delt)
Q = matrix(100, nrow=10, ncol=10)
Q[,1]= I
for (i in 1:9) {
for (j in 1:9) {
Q[i+1,j+1]=C1[i]*Q[i,j+1]+C2[i]*Q[i,j]+C3[i]*Q[i+1,j]
}
}
Q
source("~/Documents/senior_year/hydrology/HW6_3.R", echo=TRUE)
Q
plot(Q)[,1]
plot(1:10,Q[,1])
plot(1:10,Q[,1])
lines(1:10,Q[,2])
plot(1:10,Q[,1],type="l")
lines(1:10,Q[,2])
plot(1:10,Q[,1],type="l", col="red")
lines(1:10,Q[,2])
plot(1:10,Q[,3],type="l", col="red")
lines(1:10,Q[,4])
plot(1:10,Q[,1],type="l", col="red")
lines(1:10,Q[,2])
plot(1:10,Q[,5],type="l", col="red")
lines(1:10,Q[,6])
plot(1:10,Q[,9],type="l", col="red")
lines(1:10,Q[,10])
plot(1:10,Q[,7],type="l", col="red")
lines(1:10,Q[,8])
plot(1:10,Q[,9],type="l", col="red")
lines(1:10,Q[,10])
plot(1:10,Q[,7],type="l", col="red")
lines(1:10,Q[,8])
plot(1:10,Q[,9],type="l", col="red")
lines(1:10,Q[,10])
plot(1:10,Q[,7],type="l", col="red")
lines(1:10,Q[,8])
source("~/Documents/senior_year/hydrology/HW6.R", echo=TRUE)
p1
source("~/Documents/senior_year/hydrology/HW6_3.R", echo=TRUE)
Q
C1
C2
C3
source("~/Documents/senior_year/hydrology/HW6_3.R", echo=TRUE)
Q
source("~/Documents/senior_year/hydrology/HW6.R", echo=TRUE)
p1
source("~/Documents/senior_year/hydrology/HW6.R", echo=TRUE)
p1
source("~/Documents/senior_year/hydrology/HW6.R", echo=TRUE)
p1
source("~/Documents/senior_year/hydrology/HW6.R", echo=TRUE)
p1
source("~/Documents/senior_year/hydrology/HW6.R", echo=TRUE)
p1
source("~/Documents/senior_year/hydrology/HW6.R", echo=TRUE)
p1
source("~/Documents/senior_year/hydrology/HW6.R", echo=TRUE)
p1
source("~/Documents/senior_year/hydrology/HW6.R", echo=TRUE)
p1
source("~/Documents/senior_year/hydrology/HW6.R", echo=TRUE)
install.packages('matlib')
#install.packages('matlib')
library(matlib)
pA = 0.6
pB = 0.3
pC = 0.1
pDA = 0.02
pDB = 0.03
pDC = 0.04
#Solution: By the law of total probability, to find total probability P(D)
#P(D) = P(A)P(D|A) + P(B)P(D|B) + P(C)P(D|C)
#use function to calculate total probability
pD = ((pA)*(pDA))+((pB)*(pDB))+((pC)*(pDC))
print(pD)
X <- matrix(c(rep(1,6), 10, 5, 7, 19, 11, 8), ncol=2, byrow=FALSE)
y <- c(15, 9, 3, 25, 7, 13)
print(X)
print(y)
#~~~~~~~~~~PART B~~~~~~~~~
#Using OLS to find W hat
w_hat <- solve(t(X) %*% X) %*% t(X) %*% y
print(w_hat)
#~~~~~~~~~~PART C~~~~~~~~~
#To find vector of predicted values Y hat
y_hat <- X %*% w_hat
print(y_hat)
e <- y - y_hat
print(e)
#~~~~~~~~~~PART E~~~~~~~~~
#Compute the mean squared error (MSE)
mse <- mean(e^2)
print(mse)
#~~~~~~~~~~PART F~~~~~~~~~
#Compute the root mean squared error (RMSE)
rmse <- sqrt(mse)
print(rmse)
#~~~~~~~~~~PART G~~~~~~~~~
rmse <- sqrt(mse)
print(rmse)
#~~~~~~~~~~PART G~~~~~~~~~
plot(X[,2], y, main="Scatterplot with Least Squares Line", xlab="x", ylab="y")
abline(w_hat, col="red")
sigma <- function(z) {
1 / (1 + exp(-z))
}
#Plot the function in the domain z âˆˆ [-5, 5]
z <- seq(-5, 5, length.out = 100)
plot(z, sigma(z), type = "l", xlab = "z", ylab = "sigma(z)",
main = "Logistic Sigmoid Function")
source("~/Downloads/CEE697M_HW1_submitted1.R", echo=TRUE)
sigma_prime <- function(z) {
sigma_z <- sigma(z)
(1 - sigma_z) * sigma_z
}
#Finding the derivative using numerical approximation
h <- 0.0001
approx_derivative <- function(z) {
(sigma(z + h) - sigma(z - h)) / (2 * h)
}
all.equal(sigma_prime(z), approx_derivative(z), check.attributes = FALSE)
#~~~~~~~~~~Problem 5~~~~~~ Classifier Performance
#~~~~~~~~~~PART A-H~~~~~~~~
#Confusion matrix creation
conf_matrix <- matrix(c(9650, 17, 265, 68), nrow = 2, byrow = TRUE,
dimnames = list(Observed = c("Class 0", "Class 1"),
Predicted = c("Class 0", "Class 1")))
print(conf_matrix)
#Computing false positives (FP), false negatives (FN), positive observations (P), and predicted positive observations (P*)
FP <- conf_matrix["Class 0", "Class 1"]
FN <- conf_matrix["Class 1", "Class 0"]
P <- sum(conf_matrix["Class 1", ])
P_star <- sum(conf_matrix["Class 0", ])
# Computing precision, recall, F1-score, and accuracy
precision <- conf_matrix["Class 1", "Class 1"] / P_star
recall <- conf_matrix["Class 1", "Class 1"] / P
F1_score <- 2 * precision * recall / (precision + recall)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
# Printing the results of A to H
cat("False positives (FP):", FP, "\n")
cat("False negatives (FN):", FN, "\n")
cat("Positive observations (P):", P, "\n")
cat("Predicted positive observations (P*):", P_star, "\n")
cat("Test precision:", precision, "\n")
cat("Test recall:", recall, "\n")
cat("Test F1-score:", F1_score, "\n")
cat("Test accuracy:", accuracy, "\n")
#~~~~~~~~~~Problem 5~~~~~~ Classifier Performance
#~~~~~~~~~~PART A-H~~~~~~~~
#Confusion matrix creation
conf_matrix <- matrix(c(9650, 17, 265, 68), nrow = 2, byrow = TRUE,
dimnames = list(Observed = c("Class 0", "Class 1"),
Predicted = c("Class 0", "Class 1")))
print(conf_matrix)
#Computing false positives (FP), false negatives (FN), positive observations (P), and predicted positive observations (P*)
FP <- conf_matrix["Class 0", "Class 1"]
FN <- conf_matrix["Class 1", "Class 0"]
P <- sum(conf_matrix["Class 1", ])
P_star <- sum(conf_matrix["Class 0", ])
# Computing precision, recall, F1-score, and accuracy
precision <- conf_matrix["Class 1", "Class 1"] / P_star
recall <- conf_matrix["Class 1", "Class 1"] / P
F1_score <- 2 * precision * recall / (precision + recall)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
# Printing the results of A to H
cat("False positives (FP):", FP, "\n")
cat("False negatives (FN):", FN, "\n")
cat("Positive observations (P):", P, "\n")
cat("Predicted positive observations (P*):", P_star, "\n")
cat("Test precision:", precision, "\n")
cat("Test recall:", recall, "\n")
cat("Test F1-score:", F1_score, "\n")
cat("Test accuracy:", accuracy, "\n")
joint <- matrix(c(1/8, 1/16, 1/32, 1/32,
1/16, 1/8, 1/32, 1/32,
1/16, 1/16, 1/16, 1/16,
1/4, 0, 0, 0), nrow = 4, byrow = TRUE,
dimnames = list(y = c("1", "2", "3", "4"),
x = c("1", "2", "3", "4")))
joint_entropy <- -sum(joint * log2(joint))
print(paste("Joint Entropy H(X,Y) = ", joint_entropy))
#This prints out an NaN not sure why, or if this the right approach to problem
#~~~~~~~~~~PART B~~~~~~~~
#Marginal entropies
#Marginal probabilities first
marg_x <- rowSums(joint)
marg_y <- colSums(joint)
#Back to marginal entropies
H_x <- -sum(marg_x * log2(marg_x))
H_y <- -sum(marg_y * log2(marg_y))
print(paste0("Marginal Entropy H(X) = ", H_x))
print(paste0("Marginal Entropy H(Y) = ", H_y))
#~~~~~~~~~~PART C~~~~~~~~
#Entropy of X conditional on specific y value,
# script to read in raw data and organize it
library(dplyr)
library(readxl)
library(tidyr)
library(stringr)
library(stringi)
library(lubridate)
#install.packages("ggmap")
library(ggmap)
# script to read in raw data and organize it
library(dplyr)
library(readxl)
library(tidyr)
library(stringr)
library(stringi)
library(lubridate)
install.packages("ggmap")
library(ggmap)
#install.packages("ggplot2")
library(ggplot2)
setwd('/Users/emmaboudreau/Documents/GitHub/697proj/')
#setwd('/Users/samuelesquivel/Documents/GitHub/697project/')
# read in the data-----
data = read.csv('export.csv')
# script to read in raw data and organize it
library(dplyr)
library(readxl)
library(tidyr)
library(stringr)
library(stringi)
library(lubridate)
#install.packages("ggmap")
library(ggmap)
#install.packages("ggplot2")
library(ggplot2)
setwd('/Users/emmaboudreau/Documents/GitHub/697proj/')
#setwd('/Users/samuelesquivel/Documents/GitHub/697project/')
# read in the data-----
data = read.csv('export.csv')
#----
# data_munge = select(data,-c(dist_dirc_exit, age))%>%
#   filter(!is.na(speed_limit))%>% #filter out anything without speed limit
#   rename("severity" = "crash_severity_descr")%>% #changed column name
#   rename("weather" = "weath_cond_descr")%>%
#   mutate(severity=ifelse(severity=="Property damage only (none injured)",0,
#           ifelse(severity=="Non-fatal injury",1,ifelse(severity=="Fatal injury",2,3)
#            )
#           )
#          )%>%
#   filter(severity!="3")
#different ways to check number of observations for things
#filter(numb_fatal_injr!="0")
#filter(severity=="1")
#none injured = 0, non fatal = 1, fatal = 2
#removed unreported or unknown
#---- 1 dataframe we could use
data2 = select(data,-c(dist_dirc_exit, age, max_injr_svrty_cl,
numb_fatal_injr, numb_nonfatal_injr,injy_stat_descr,
vehc_unit_numb,crash_status,max_injr_svrty_vl, pers_numb))%>%
filter(!is.na(speed_limit))%>% #filter out anything without speed limit
rename("severity" = "crash_severity_descr")%>% #changed column name
rename("weather" = "weath_cond_descr")%>%
mutate(severity=ifelse(severity=="Property damage only (none injured)",0,
ifelse(severity=="Non-fatal injury",1,ifelse(severity=="Fatal injury",2,3)
)
)
)%>%
filter(severity!="3")%>% #remove any unreported or unknown severity levels
filter(severity!="2")%>% #remove fatal injuries
drop_na()%>% #drop any row with NA
mutate(weather = ifelse(weather =="Clear/Clear","Clear",ifelse(weather == "Rain/Rain","Rain",
ifelse(weather=="Not Reported","Unknown",ifelse(weather=="Snow/Snow","Snow",
ifelse(weather=="Cloudy/Rain","Rain",ifelse(weather=="Clear/Cloudy", "Cloudy",
ifelse(weather=="Snow/Cloudy","Snow",ifelse(weather=="Clear/Blowing sand, snow","Snow",
ifelse(weather=="Rain/Sleet, hail (freezing rain or drizzle)","Rain", ifelse(weather=="Snow/Blowing sand, snow", "Snow",
ifelse(weather=="Clear/Rain","Rain",ifelse(weather=="Cloudy/Cloudy","Cloudy",
ifelse(weather=="Rain/Cloudy","Rain",ifelse(weather=="Rain/Severe crosswinds","Rain",
ifelse(weather=="Snow/Sleet, hail (freezing rain or drizzle)", "Snow",weather)))))))))))
)))))%>% #concatenating weather conditions
mutate(weather=ifelse(weather=="Clear",0,
ifelse(weather=="Cloudy",1,ifelse(weather=="Snow",2,
ifelse(weather=="Rain",3,
ifelse(weather=="Unknown",5,6)
)
)
)
)
)%>% #creating numerical code for different weather conditions
#filter(weather!="5")
filter(weather!="5")%>% #filtering out any unknown or other weather descriptions that are not frequently used/ambiguous
filter(weather!="6")
WS<-as.Date("12/15/2018", format=  "%m/%d/%Y") #winter solstice
SE<-as.Date("03/15/2018", format=  "%m/%d/%Y") #spring equinox
SS<-as.Date("06/15/2018", format=  "%m/%d/%Y") #summer solstice
FE<-as.Date("09/15/2018", format=  "%m/%d/%Y") #fall equinox
#seasons code: winter = 0, spring = 1, summer = 2, fall = 3
data3 = data2%>%
rename("date"="crash_date")%>%
mutate(date = as.Date(date,format= "%m/%d/%Y"))%>%
mutate(season = ifelse(date>=WS | date<SE, "0", ifelse(date>=SE & date< SS, "1",
ifelse(date>=SS&date< FE, "2", "3"))))
####sam's additions below,###
###REGARDING TIME###
#step 1
#convert existing date and time to standard POSIX format
data3 <- data3 %>%
mutate(crash_time_2 = str_replace(crash_time_2, "\\s(AM|PM)", " \\1"),  # Remove the space before AM/PM
crash_time_2 = as.POSIXct(crash_time_2, format = "%I:%M %p"),  # Convert to POSIXct format
crash_date = as.Date(date))  # Convert 'date' to Date format
data3 <- data3 %>%
mutate(crash_date_time_standard = as.POSIXct(paste(crash_date, format(crash_time_2, "%H:%M:%S")), format = "%Y-%m-%d %H:%M:%S"))
#step 2
#drop the excess columns we don't need anymore and make new polished data frame
data4 <- data3 %>%
select(-crash_date, -date, -crash_time_2)
#drop_na2()%>% #drop any row with NA
#step 3
#do some analysis on the timing of events
#extract the hour from the crash_date_time_standard column
data4 <- data4 %>%
mutate(hour = hour(crash_date_time_standard))
#calculate the crash count for each hour
crash_count <- data4 %>%
count(hour)
#plot the crash count by hour
plot(crash_count$hour, crash_count$n, type = "l", xlab = "Hour of Day", ylab = "Crash Count", main = "Crash Count by Hour")
###REGARDING LOCATION###
# Load required libraries
library(ggplot2)
library(ggmap)
#set the latitude and longitude boundaries for Boston area
boston_bounds <- c(left = -71.1912, bottom = 42.2279, right = -70.8085, top = 42.3974)
#get the map background using ggmap and specify the map type
boston_map <- get_stamenmap(boston_bounds, maptype = "toner-lite")
#plot the map of Boston
ggmap(boston_map) +
#add points representing crash locations
geom_point(data = data4, aes(x = lon, y = lat), color = "red", alpha = 0.5) +
#adjust the transparency and color of the points
guides(alpha = FALSE) +
labs(title = "Crashes in Boston, MA") +
theme(plot.title = element_text(hjust = 0.5))
View(data4)
View(data4)
